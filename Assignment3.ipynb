{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "private_outputs": true,
      "gpuType": "T4",
      "mount_file_id": "1MY6nO4cM3oCxmzlmpSL3p1Nv9TTdCaIL",
      "authorship_tag": "ABX9TyMj6YMGdfm9AvCpfaAKD0mz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hsahni55h/Advance_machine_learning_with_neural_networks_TIF360/blob/main/Assignment3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nmXvUV6s4dIR"
      },
      "outputs": [],
      "source": [
        "!pip -q install deeptrack\n",
        "\n",
        "\n",
        "import deeptrack as dt\n",
        "import numpy as np\n",
        "from google.colab import drive\n",
        "\n",
        "generate_new_dataset = False\n",
        "IMAGE_SIZE = 64\n",
        "sequence_length=10\n",
        "\n",
        "if generate_new_dataset:\n",
        "  IMAGE_SIZE = 64\n",
        "  sequence_length = 10  # Number of frames per sequence\n",
        "  MIN_SIZE = 0.5e-6\n",
        "  MAX_SIZE = 1.5e-6\n",
        "  MAX_VEL = 10  # Maximum velocity. The higher the trickier!\n",
        "  MAX_PARTICLES = 3  # Max number of particles in each sequence. The higher the trickier!\n",
        "\n",
        "  # Defining properties of the particles\n",
        "  particle = dt.Sphere(\n",
        "      intensity=lambda: 10 + 10 * np.random.rand(),\n",
        "      radius=lambda: MIN_SIZE + np.random.rand() * (MAX_SIZE - MIN_SIZE),\n",
        "      position=lambda: IMAGE_SIZE * np.random.rand(2),\n",
        "      vel=lambda: MAX_VEL * np.random.rand(2),\n",
        "      position_unit=\"pixel\",\n",
        "  )\n",
        "\n",
        "  # Defining an update rule for the particle position\n",
        "  def get_position(previous_value, vel):\n",
        "\n",
        "      newv = previous_value + vel\n",
        "      for i in range(2):\n",
        "          if newv[i] > 63:\n",
        "              newv[i] = 63 - np.abs(newv[i] - 63)\n",
        "              vel[i] = -vel[i]\n",
        "          elif newv[i] < 0:\n",
        "              newv[i] = np.abs(newv[i])\n",
        "              vel[i] = -vel[i]\n",
        "      return newv\n",
        "\n",
        "\n",
        "  particle = dt.Sequential(particle, position=get_position)\n",
        "\n",
        "  # Defining properties of the microscope\n",
        "  optics = dt.Fluorescence(\n",
        "      NA=1,\n",
        "      output_region=(0, 0, IMAGE_SIZE, IMAGE_SIZE),\n",
        "      magnification=10,\n",
        "      resolution=(1e-6, 1e-6, 1e-6),\n",
        "      wavelength=633e-9,\n",
        "  )\n",
        "\n",
        "  # Combining everything into a dataset.\n",
        "  # Note that the sequences are flipped in different directions, so that each unique sequence defines\n",
        "  # in fact 8 sequences flipped in different directions, to speed up data generation\n",
        "  sequential_images = dt.Sequence(\n",
        "      optics(particle ** (lambda: 1 + np.random.randint(MAX_PARTICLES))),\n",
        "      sequence_length=sequence_length,\n",
        "  )\n",
        "  dataset = sequential_images >> dt.FlipUD() >> dt.FlipDiagonal() >> dt.FlipLR()\n",
        "  #dataset.update().plot(cmap=\"gray\") #This generates a new sequence and plots it\n",
        "  video = dataset.update().resolve() #This generates a new sequence and stores in in \"video\"\n",
        "  def get_data(data_amount):\n",
        "    frames = []\n",
        "\n",
        "    for _ in range(data_amount):\n",
        "      video = dataset.update().resolve() # Get a new sequence of frames\n",
        "      for frame in video:\n",
        "        frames.append(frame)\n",
        "\n",
        "    return tf.stack(frames)\n",
        "\n",
        "  data_amount = 1000\n",
        "  # Generate new data and save to file\n",
        "  ball_data = get_data(data_amount)\n",
        "  np.save('ball_data.npy', ball_data)\n",
        "  \n",
        "else:\n",
        "  drive.mount('/content/drive')\n",
        "  ball_data = np.load('/content/drive/MyDrive/ball_data.npy')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Task 1"
      ],
      "metadata": {
        "id": "tGqLNkNJ5UCt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "Layer=keras.layers.Layer"
      ],
      "metadata": {
        "id": "FJpGjE9b7Ggt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# neck_width = 128"
      ],
      "metadata": {
        "id": "Fvu74IQm7dWf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "neck_width = 64 # for 4 filters in the last convolutional layer in encoder\n",
        "filters = 4\n",
        "\n",
        "class Autoencoder(tf.keras.Model):\n",
        "  def __init__(self):\n",
        "    super(Autoencoder, self).__init__()\n",
        "    self.encoder = tf.keras.Sequential([\n",
        "      tf.keras.layers.Input(shape=(IMAGE_SIZE, IMAGE_SIZE, 1)),\n",
        "      tf.keras.layers.Conv2D(64, (8, 8), padding='same', strides=(4, 4), activation='relu'),\n",
        "      tf.keras.layers.Conv2D(filters, (4, 4), padding='same', strides=(4, 4), activation='relu'),\n",
        "      tf.keras.layers.Flatten()\n",
        "    ])\n",
        "\n",
        "    self.decoder = tf.keras.Sequential([\n",
        "      tf.keras.layers.Input(shape=(neck_width, )),\n",
        "      tf.keras.layers.Reshape(target_shape=(4, 4, filters)),\n",
        "      tf.keras.layers.Conv2DTranspose(filters, (4, 4), strides=(4, 4), activation='relu', padding='same'),\n",
        "      tf.keras.layers.Conv2DTranspose(64, (8, 8), strides=(4, 4), activation='relu', padding='same'),\n",
        "      tf.keras.layers.Conv2D(1, (1, 1), activation='linear', padding='same')\n",
        "    ])\n",
        "\n",
        "  def call(self, x):\n",
        "    encoded = self.encoder(x)\n",
        "    decoded = self.decoder(encoded)\n",
        "    return decoded\n",
        "\n",
        "autoencoder = Autoencoder()\n",
        "autoencoder.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "autoencoder.encoder.build(input_shape=(None, 64, 64, 1))\n",
        "autoencoder.encoder.summary()\n",
        "\n",
        "autoencoder.decoder.build(input_shape=(None, neck_width))\n",
        "autoencoder.decoder.summary()"
      ],
      "metadata": {
        "id": "Prqw5MMU5UG6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_frames = len(ball_data) \n",
        "ratio = 0.8 # training data to validation/test data ratio\n",
        "train_test_split = [int(n_frames*ratio), n_frames-int(n_frames*ratio)]\n",
        "\n",
        "x_train, x_val = tf.split(ball_data, train_test_split)\n",
        "\n",
        "max_val = tf.reduce_max(tf.concat([x_train, x_val], 0))\n",
        "x_train /= max_val\n",
        "x_val /= max_val\n",
        "\n",
        "print(\"Training data size:\", x_train.shape)\n",
        "print(\"Validation data size:\", x_val.shape)\n"
      ],
      "metadata": {
        "id": "Mobosk5w5UJf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n",
        "                                            min_delta=0,\n",
        "                                            patience=3,\n",
        "                                            verbose=1,\n",
        "                                            mode='auto',\n",
        "                                            baseline=None,\n",
        "                                            restore_best_weights=True)\n",
        "autoencoder.fit(x_train, x_train,\n",
        "                 batch_size=32,\n",
        "                 epochs=50,\n",
        "                 shuffle=True,\n",
        "                 validation_data=(x_val, x_val),\n",
        "                 callbacks=[callback])\n",
        "\n",
        "autoencoder.save('autoencoder_'+str(neck_width))"
      ],
      "metadata": {
        "id": "-6kX4W_65UMJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "autoencoder = tf.keras.models.load_model('autoencoder_64')\n",
        "\n",
        "n = sequence_length  # how many digits we will display\n",
        "rand_sequence = 0#np.random.randint(len(x_val)/sequence_length)\n",
        "\n",
        "seq_start = rand_sequence * sequence_length\n",
        "\n",
        "org_frames = x_val[seq_start : seq_start + sequence_length]\n",
        "encoded_imgs = autoencoder.encoder(org_frames).numpy()\n",
        "decoded_imgs = autoencoder.decoder(encoded_imgs).numpy()\n",
        "\n",
        "plt.figure(figsize=(20, 4))\n",
        "for i in range(sequence_length):\n",
        "  # display original\n",
        "  ax = plt.subplot(2, n, i + 1)\n",
        "  plt.imshow(tf.squeeze(org_frames[i]))\n",
        "  plt.title(\"original\")\n",
        "  plt.gray()\n",
        "  ax.get_xaxis().set_visible(False)\n",
        "  ax.get_yaxis().set_visible(False)\n",
        "\n",
        "  # display reconstruction\n",
        "  ax = plt.subplot(2, n, i + 1 + n)\n",
        "  plt.imshow(tf.squeeze(decoded_imgs[i]))\n",
        "  plt.title(\"reconstructed\")\n",
        "  plt.gray()\n",
        "  ax.get_xaxis().set_visible(False)\n",
        "  ax.get_yaxis().set_visible(False)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "9H5zwapb7TYw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# neck_width = 128"
      ],
      "metadata": {
        "id": "Tv5a4fxP7TcW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "neck_width = 128 # for 8 filters in the last convolutional layer in encoder\n",
        "filters = 8\n",
        "\n",
        "class Autoencoder(tf.keras.Model):\n",
        "  def __init__(self):\n",
        "    super(Autoencoder, self).__init__()\n",
        "    self.encoder = tf.keras.Sequential([\n",
        "      tf.keras.layers.Input(shape=(IMAGE_SIZE, IMAGE_SIZE, 1)),\n",
        "      tf.keras.layers.Conv2D(64, (8, 8), padding='same', strides=(4, 4), activation='relu'),\n",
        "      tf.keras.layers.Conv2D(filters, (4, 4), padding='same', strides=(4, 4), activation='relu'),\n",
        "      tf.keras.layers.Flatten()\n",
        "    ])\n",
        "\n",
        "    self.decoder = tf.keras.Sequential([\n",
        "      tf.keras.layers.Input(shape=(neck_width, )),\n",
        "      tf.keras.layers.Reshape(target_shape=(4, 4, filters)),\n",
        "      tf.keras.layers.Conv2DTranspose(filters, (4, 4), strides=(4, 4), activation='relu', padding='same'),\n",
        "      tf.keras.layers.Conv2DTranspose(64, (8, 8), strides=(4, 4), activation='relu', padding='same'),\n",
        "      tf.keras.layers.Conv2D(1, (1, 1), activation='linear', padding='same')\n",
        "    ])\n",
        "\n",
        "  def call(self, x):\n",
        "    encoded = self.encoder(x)\n",
        "    decoded = self.decoder(encoded)\n",
        "    return decoded\n",
        "\n",
        "autoencoder = Autoencoder()\n",
        "autoencoder.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "autoencoder.encoder.build(input_shape=(None, 64, 64, 1))\n",
        "autoencoder.encoder.summary()\n",
        "\n",
        "autoencoder.decoder.build(input_shape=(None, neck_width))\n",
        "autoencoder.decoder.summary()"
      ],
      "metadata": {
        "id": "XaxOL5DS7Tdo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_frames = len(ball_data) \n",
        "ratio = 0.8 # training data to validation/test data ratio\n",
        "train_test_split = [int(n_frames*ratio), n_frames-int(n_frames*ratio)]\n",
        "\n",
        "x_train, x_val = tf.split(ball_data, train_test_split)\n",
        "\n",
        "max_val = tf.reduce_max(tf.concat([x_train, x_val], 0))\n",
        "x_train /= max_val\n",
        "x_val /= max_val\n",
        "\n",
        "print(\"Training data size:\", x_train.shape)\n",
        "print(\"Validation data size:\", x_val.shape)\n"
      ],
      "metadata": {
        "id": "rxjgYK8P7hVK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n",
        "                                            min_delta=0,\n",
        "                                            patience=3,\n",
        "                                            verbose=1,\n",
        "                                            mode='auto',\n",
        "                                            baseline=None,\n",
        "                                            restore_best_weights=True)\n",
        "autoencoder.fit(x_train, x_train,\n",
        "                 batch_size=32,\n",
        "                 epochs=50,\n",
        "                 shuffle=True,\n",
        "                 validation_data=(x_val, x_val),\n",
        "                 callbacks=[callback])\n",
        "\n",
        "autoencoder.save('autoencoder_'+str(neck_width))"
      ],
      "metadata": {
        "id": "Bu2cGSwz7hga"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "autoencoder = tf.keras.models.load_model('autoencoder_128')\n",
        "\n",
        "n = sequence_length  # how many digits we will display\n",
        "rand_sequence = 0#np.random.randint(len(x_val)/sequence_length)\n",
        "\n",
        "seq_start = rand_sequence * sequence_length\n",
        "\n",
        "org_frames = x_val[seq_start : seq_start + sequence_length]\n",
        "encoded_imgs = autoencoder.encoder(org_frames).numpy()\n",
        "decoded_imgs = autoencoder.decoder(encoded_imgs).numpy()\n",
        "\n",
        "plt.figure(figsize=(20, 4))\n",
        "for i in range(sequence_length):\n",
        "  # display original\n",
        "  ax = plt.subplot(2, n, i + 1)\n",
        "  plt.imshow(tf.squeeze(org_frames[i]))\n",
        "  plt.title(\"original\")\n",
        "  plt.gray()\n",
        "  ax.get_xaxis().set_visible(False)\n",
        "  ax.get_yaxis().set_visible(False)\n",
        "\n",
        "  # display reconstruction\n",
        "  ax = plt.subplot(2, n, i + 1 + n)\n",
        "  plt.imshow(tf.squeeze(decoded_imgs[i]))\n",
        "  plt.title(\"reconstructed\")\n",
        "  plt.gray()\n",
        "  ax.get_xaxis().set_visible(False)\n",
        "  ax.get_yaxis().set_visible(False)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "E5pl9_ju7hm2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# neck_width = 256"
      ],
      "metadata": {
        "id": "y-6Xk0BT7TfH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "neck_width = 256 # for 16 filters in the last convolutional layer in encoder\n",
        "filters = 16 \n",
        "\n",
        "class Autoencoder(tf.keras.Model):\n",
        "  def __init__(self):\n",
        "    super(Autoencoder, self).__init__()\n",
        "    self.encoder = tf.keras.Sequential([\n",
        "      tf.keras.layers.Input(shape=(IMAGE_SIZE, IMAGE_SIZE, 1)),\n",
        "      tf.keras.layers.Conv2D(64, (8, 8), padding='same', strides=(4, 4), activation='relu'),\n",
        "      tf.keras.layers.Conv2D(filters, (4, 4), padding='same', strides=(4, 4), activation='relu'),\n",
        "      tf.keras.layers.Flatten()\n",
        "    ])\n",
        "\n",
        "    self.decoder = tf.keras.Sequential([\n",
        "      tf.keras.layers.Input(shape=(neck_width, )),\n",
        "      tf.keras.layers.Reshape(target_shape=(4, 4, filters)),\n",
        "      tf.keras.layers.Conv2DTranspose(filters, (4, 4), strides=(4, 4), activation='relu', padding='same'),\n",
        "      tf.keras.layers.Conv2DTranspose(64, (8, 8), strides=(4, 4), activation='relu', padding='same'),\n",
        "      tf.keras.layers.Conv2D(1, (1, 1), activation='linear', padding='same')\n",
        "    ])\n",
        "\n",
        "  def call(self, x):\n",
        "    encoded = self.encoder(x)\n",
        "    decoded = self.decoder(encoded)\n",
        "    return decoded\n",
        "\n",
        "autoencoder = Autoencoder()\n",
        "autoencoder.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "autoencoder.encoder.build(input_shape=(None, 64, 64, 1))\n",
        "autoencoder.encoder.summary()\n",
        "\n",
        "autoencoder.decoder.build(input_shape=(None, neck_width))\n",
        "autoencoder.decoder.summary()"
      ],
      "metadata": {
        "id": "K3JhfLch7Tgg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_frames = len(ball_data) \n",
        "ratio = 0.8 # training data to validation/test data ratio\n",
        "train_test_split = [int(n_frames*ratio), n_frames-int(n_frames*ratio)]\n",
        "\n",
        "x_train, x_val = tf.split(ball_data, train_test_split)\n",
        "\n",
        "max_val = tf.reduce_max(tf.concat([x_train, x_val], 0))\n",
        "x_train /= max_val\n",
        "x_val /= max_val\n",
        "\n",
        "print(\"Training data size:\", x_train.shape)\n",
        "print(\"Validation data size:\", x_val.shape)\n"
      ],
      "metadata": {
        "id": "k_tbaMau7TiI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n",
        "                                            min_delta=0,\n",
        "                                            patience=3,\n",
        "                                            verbose=1,\n",
        "                                            mode='auto',\n",
        "                                            baseline=None,\n",
        "                                            restore_best_weights=True)\n",
        "autoencoder.fit(x_train, x_train,\n",
        "                 batch_size=32,\n",
        "                 epochs=50,\n",
        "                 shuffle=True,\n",
        "                 validation_data=(x_val, x_val),\n",
        "                 callbacks=[callback])\n",
        "\n",
        "autoencoder.save('autoencoder_'+str(neck_width))"
      ],
      "metadata": {
        "id": "YRCZ-z-F7Tj4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "autoencoder = tf.keras.models.load_model('autoencoder_256')\n",
        "\n",
        "n = sequence_length  # how many digits we will display\n",
        "rand_sequence = 0   #np.random.randint(len(x_val)/sequence_length)\n",
        "\n",
        "seq_start = rand_sequence * sequence_length\n",
        "\n",
        "org_frames = x_val[seq_start : seq_start + sequence_length]\n",
        "encoded_imgs = autoencoder.encoder(org_frames).numpy()\n",
        "decoded_imgs = autoencoder.decoder(encoded_imgs).numpy()\n",
        "\n",
        "plt.figure(figsize=(20, 4))\n",
        "for i in range(sequence_length):\n",
        "  # display original\n",
        "  ax = plt.subplot(2, n, i + 1)\n",
        "  plt.imshow(tf.squeeze(org_frames[i]))\n",
        "  plt.title(\"original\")\n",
        "  plt.gray()\n",
        "  ax.get_xaxis().set_visible(False)\n",
        "  ax.get_yaxis().set_visible(False)\n",
        "\n",
        "  # display reconstruction\n",
        "  ax = plt.subplot(2, n, i + 1 + n)\n",
        "  plt.imshow(tf.squeeze(decoded_imgs[i]))\n",
        "  plt.title(\"reconstructed\")\n",
        "  plt.gray()\n",
        "  ax.get_xaxis().set_visible(False)\n",
        "  ax.get_yaxis().set_visible(False)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "s57v-AKn7TmC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !cp -r /content/drive/MyDrive/Colab\\ Notebooks/autoencoder_256 .\n",
        "# !cp -r /content/drive/MyDrive/Colab\\ Notebooks/autoencoder_128 .\n",
        "# !cp -r /content/drive/MyDrive/Colab\\ Notebooks/autoencoder_64 ."
      ],
      "metadata": {
        "id": "18DZo4YVL8L4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "autoencoder = tf.keras.models.load_model('autoencoder_256')\n",
        "loss = autoencoder.evaluate(x_val, x_val)\n",
        "print(\"Loss for Bottleneck-256:\", loss)\n",
        "\n",
        "autoencoder = tf.keras.models.load_model('autoencoder_128')\n",
        "loss = autoencoder.evaluate(x_val, x_val)\n",
        "print(\"Loss for Bottleneck-128:\", loss)\n",
        "\n",
        "autoencoder = tf.keras.models.load_model('autoencoder_64')\n",
        "loss = autoencoder.evaluate(x_val, x_val)\n",
        "print(\"Loss for Bottleneck-64:\", loss)"
      ],
      "metadata": {
        "id": "gMHw2P5zFsNd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Task 2"
      ],
      "metadata": {
        "id": "0XA6sWkz7Tnw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import tensorflow as tf\n",
        "# drive.mount('/content/drive')\n",
        "# autoencoder_256 = tf.keras.models.load_model('/content/drive/MyDrive/autoencoder_256')\n",
        "autoencoder_256 = tf.keras.models.load_model('autoencoder_256')"
      ],
      "metadata": {
        "id": "y23IFEH4jFKI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameters\n",
        "neck_width = 256\n",
        "\n",
        "latent_dim = neck_width\n",
        "d_k = 256\n",
        "d_v = 256\n",
        "n_heads = 12\n",
        "ff_dim = 256\n",
        "filt_dim = latent_dim+2\n",
        "seq_len = 9"
      ],
      "metadata": {
        "id": "6Dx2M9jn7Tpm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "Layer=keras.layers.Layer\n",
        "\n",
        "class Time2Vector(Layer): #Time embedding layer\n",
        "  def __init__(self, seq_len, **kwargs):\n",
        "    super(Time2Vector, self).__init__()\n",
        "    self.seq_len = seq_len\n",
        "\n",
        "  def build(self, input_shape):\n",
        "    self.weights_linear = self.add_weight(name='weight_linear',\n",
        "                                shape=(int(self.seq_len),),\n",
        "                                initializer='uniform',\n",
        "                                trainable=True)\n",
        "    \n",
        "    self.bias_linear = self.add_weight(name='bias_linear',\n",
        "                                shape=(int(self.seq_len),),\n",
        "                                initializer='uniform',\n",
        "                                trainable=True)\n",
        "    \n",
        "    self.weights_periodic = self.add_weight(name='weight_periodic',\n",
        "                                shape=(int(self.seq_len),),\n",
        "                                initializer='uniform',\n",
        "                                trainable=True)\n",
        "\n",
        "    self.bias_periodic = self.add_weight(name='bias_periodic',\n",
        "                                shape=(int(self.seq_len),),\n",
        "                                initializer='uniform',\n",
        "                                trainable=True)\n",
        "\n",
        "  def call(self, x):\n",
        "    x = tf.math.reduce_mean(x[:,:,:], axis=-1) # Convert (batch, seq_len, 5) to (batch, seq_len)\n",
        "    time_linear = self.weights_linear * x + self.bias_linear\n",
        "    time_linear = tf.expand_dims(time_linear, axis=-1) # (batch, seq_len, 1)\n",
        "    \n",
        "    time_periodic = tf.math.sin(tf.multiply(x, self.weights_periodic) + self.bias_periodic)\n",
        "    time_periodic = tf.expand_dims(time_periodic, axis=-1) # (batch, seq_len, 1)\n",
        "    return tf.concat([time_linear, time_periodic], axis=-1) # (batch, seq_len, 2)\n",
        "    \n",
        "class SingleAttention(Layer): #Attention layer\n",
        "  def __init__(self, d_k, d_v):\n",
        "    super(SingleAttention, self).__init__()\n",
        "    self.d_k = d_k\n",
        "    self.d_v = d_v\n",
        "\n",
        "  def build(self, input_shape):\n",
        "    self.query = tf.keras.layers.Dense(self.d_k, input_shape=input_shape, kernel_initializer='glorot_uniform', bias_initializer='glorot_uniform')\n",
        "    self.key = tf.keras.layers.Dense(self.d_k, input_shape=input_shape, kernel_initializer='glorot_uniform', bias_initializer='glorot_uniform')\n",
        "    self.value = tf.keras.layers.Dense(self.d_v, input_shape=input_shape, kernel_initializer='glorot_uniform', bias_initializer='glorot_uniform')\n",
        "\n",
        "  def call(self, inputs): # inputs = (in_seq, in_seq, in_seq)\n",
        "    q = self.query(inputs[0])\n",
        "    k = self.key(inputs[1])\n",
        "\n",
        "    attn_weights = tf.matmul(q, k, transpose_b=True)\n",
        "    attn_weights = tf.map_fn(lambda x: x/np.sqrt(self.d_k), attn_weights)\n",
        "    attn_weights = tf.nn.softmax(attn_weights, axis=-1)\n",
        "    \n",
        "    v = self.value(inputs[2])\n",
        "    attn_out = tf.matmul(attn_weights, v)\n",
        "    return attn_out \n",
        "\n",
        "class MultiAttention(Layer): #Multihead attention\n",
        "  def __init__(self, d_k, d_v, n_heads,filt_dim):\n",
        "    super(MultiAttention, self).__init__()\n",
        "    self.d_k = d_k\n",
        "    self.d_v = d_v\n",
        "    self.n_heads = n_heads\n",
        "    self.filt_dim=filt_dim\n",
        "    self.attn_heads = list()\n",
        "\n",
        "  def build(self, input_shape):\n",
        "    for n in range(self.n_heads):\n",
        "      self.attn_heads.append(SingleAttention(self.d_k, self.d_v))  \n",
        "    self.linear = tf.keras.layers.Dense(self.filt_dim, input_shape=input_shape, kernel_initializer='glorot_uniform', bias_initializer='glorot_uniform')\n",
        "\n",
        "  def call(self, inputs):\n",
        "    attn = [self.attn_heads[i](inputs) for i in range(self.n_heads)]\n",
        "    concat_attn = tf.concat(attn, axis=-1)\n",
        "    multi_linear = self.linear(concat_attn)\n",
        "    return multi_linear\n",
        "\n",
        "class TransformerEncoder(Layer): #Combining everything into a Transformer encoder\n",
        "  def __init__(self, d_k, d_v, n_heads, ff_dim,filt_dim, dropout=0.1, **kwargs):\n",
        "    super(TransformerEncoder, self).__init__()\n",
        "    self.d_k = d_k\n",
        "    self.d_v = d_v\n",
        "    self.n_heads = n_heads\n",
        "    self.ff_dim = ff_dim\n",
        "    self.filt_dim=filt_dim\n",
        "    self.attn_heads = list()\n",
        "    self.dropout_rate = dropout\n",
        "\n",
        "  def build(self, input_shape):\n",
        "    self.attn_multi = MultiAttention(self.d_k, self.d_v, self.n_heads,self.filt_dim)\n",
        "    self.attn_dropout = tf.keras.layers.Dropout(self.dropout_rate)\n",
        "    self.attn_normalize = tf.keras.layers.LayerNormalization(input_shape=input_shape, epsilon=1e-6)\n",
        "\n",
        "    self.ff_conv1D_1 = tf.keras.layers.Conv1D(filters=self.ff_dim, kernel_size=1, activation='relu')\n",
        "    self.ff_conv1D_2 = tf.keras.layers.Conv1D(filters=self.filt_dim, kernel_size=1) # input_shape[0]=(batch, seq_len, 7), input_shape[0][-1]=7 \n",
        "    self.ff_dropout = tf.keras.layers.Dropout(self.dropout_rate)\n",
        "    self.ff_normalize = tf.keras.layers.LayerNormalization(input_shape=input_shape, epsilon=1e-6)    \n",
        "  \n",
        "  def call(self, inputs): # inputs = (in_seq, in_seq, in_seq)\n",
        "    attn_layer = self.attn_multi(inputs)\n",
        "    attn_layer = self.attn_dropout(attn_layer)\n",
        "    attn_layer = self.attn_normalize(inputs[0] + attn_layer)\n",
        "\n",
        "    ff_layer = self.ff_conv1D_1(attn_layer)\n",
        "    ff_layer = self.ff_conv1D_2(ff_layer)\n",
        "    ff_layer = self.ff_dropout(ff_layer)\n",
        "    ff_layer = self.ff_normalize(inputs[0] + ff_layer)\n",
        "    return ff_layer "
      ],
      "metadata": {
        "id": "4_8gdUVvmjY0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "autoencoder = tf.keras.models.load_model('autoencoder_256')\n",
        "autoencoder.trainable = False\n",
        "autoencoder.encoder.trainable = False\n",
        "autoencoder.decoder.trainable = False\n",
        "\n",
        "def create_model(neck_width):\n",
        "    filt_dim = neck_width + 2\n",
        "\n",
        "    time_embedding = Time2Vector(seq_len)\n",
        "    attn_layer1 = TransformerEncoder(d_k, d_v, n_heads, ff_dim, filt_dim)\n",
        "    attn_layer2 = TransformerEncoder(d_k, d_v, n_heads, ff_dim, filt_dim)\n",
        "    attn_layer3 = TransformerEncoder(d_k, d_v, n_heads, ff_dim, filt_dim)\n",
        "\n",
        "    in_seq = tf.keras.layers.Input(shape=(seq_len, neck_width))\n",
        "    x = time_embedding(in_seq)\n",
        "    x = tf.keras.layers.Concatenate(axis=-1)([in_seq, x])\n",
        "    x = attn_layer1((x, x, x))\n",
        "    x = attn_layer2((x, x, x))\n",
        "    x = attn_layer3((x, x, x))\n",
        "    x = tf.keras.layers.GlobalAveragePooling1D()(x)\n",
        "    x = tf.keras.layers.Dropout(0.1)(x)\n",
        "    x = tf.keras.layers.Dense(128, activation='relu')(x)\n",
        "    x = tf.keras.layers.Dropout(0.1)(x)\n",
        "    x = tf.keras.layers.Dense(latent_dim, activation='linear')(x)\n",
        "    out = tf.keras.layers.LeakyReLU()(x)\n",
        "    #out = autoencoder.decoder(x)\n",
        "\n",
        "    model = tf.keras.Model(inputs=in_seq, outputs=out)\n",
        "    #model.compile(loss='mse', optimizer='adam', metrics=['mae', 'mape'])\n",
        "    model.compile(optimizer='adam', loss=keras.losses.MeanSquaredError())\n",
        "    return model\n",
        "\n",
        "model = create_model(neck_width)\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "N_qUeU6L7TrG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocessing"
      ],
      "metadata": {
        "id": "VUSwSm6v7Tsx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# encoded data\n",
        "comp_train = autoencoder.encoder(x_train)\n",
        "comp_val   = autoencoder.encoder(x_val)\n",
        "\n",
        "# split data into sequences\n",
        "print(comp_train.shape)\n",
        "print(comp_val.shape)\n",
        "comp_train_reshaped = tf.reshape(comp_train,(80,sequence_length,neck_width))\n",
        "comp_train_y_reshaped = tf.reshape(x_train,(80,sequence_length,64,64,1))\n",
        "\n",
        "train_x = comp_train_reshaped[:,0:9,:]\n",
        "train_y = comp_train_reshaped[:,9,:]\n",
        "print(train_x.shape)\n",
        "print(train_y.shape)\n",
        "\n",
        "comp_val_reshaped   = tf.reshape(comp_val,(20,sequence_length,neck_width))\n",
        "comp_val_y_reshaped = tf.reshape(x_val,(20,sequence_length, 64,64,1))\n",
        "\n",
        "val_x = comp_val_reshaped[:,0:9,:]\n",
        "val_y = comp_val_reshaped[:,9,:]\n",
        "print(val_x.shape)\n",
        "print(val_y.shape)"
      ],
      "metadata": {
        "id": "9IZnrqTs7TuQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training"
      ],
      "metadata": {
        "id": "SUSHn1m6nGrx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n",
        "                                            min_delta=0,\n",
        "                                            patience=3,\n",
        "                                            verbose=1,\n",
        "                                            mode='auto',\n",
        "                                            baseline=None,\n",
        "                                            restore_best_weights=True)\n",
        "model.fit(train_x, train_y, \n",
        "                 batch_size=32,\n",
        "                 epochs=500,\n",
        "                 shuffle=True,\n",
        "                 validation_data=(val_x, val_y)\n",
        "                 )\n",
        "\n",
        "model.save('transformer_encoder')"
      ],
      "metadata": {
        "id": "GPGgzdtq7Tv2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.models.load_model('transformer_encoder')\n",
        "autoencoder = tf.keras.models.load_model('autoencoder_256')"
      ],
      "metadata": {
        "id": "5EbIpDZt7Txs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training set"
      ],
      "metadata": {
        "id": "y2-UKtoanXiA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n = 10\n",
        "plt.figure(figsize=(20, 4))\n",
        "for i in range(n):\n",
        "    y_pred = model.predict(train_x[i:i+1])\n",
        "    #print(tf.squeeze(autoencoder.decoder(y_pred)).shape)\n",
        "    plt.subplot(2, n, i + 1)\n",
        "    plt.title(\"Prediction\")\n",
        "    plt.imshow(tf.squeeze(autoencoder.decoder(y_pred)), cmap='gray')\n",
        "    plt.subplot(2, n, i + 1 + n)\n",
        "    a = tf.reshape(train_y[i],[1,256])\n",
        "    #print(autoencoder.decoder(a).shape)\n",
        "    plt.title(\"original\")\n",
        "    plt.imshow(tf.squeeze(autoencoder.decoder(a)), cmap='gray')"
      ],
      "metadata": {
        "id": "zkWgXLrE7T0E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test set"
      ],
      "metadata": {
        "id": "IOJlKbNb7T1x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(val_x[0].shape)\n",
        "n = 10\n",
        "plt.figure(figsize=(20, 4))\n",
        "for i in range(n):\n",
        "    #print(val_x[i:i+1].shape)\n",
        "    y_pred = model.predict(val_x[i:i+1])\n",
        "    #print(tf.squeeze(autoencoder.decoder(y_pred)).shape)\n",
        "    plt.subplot(2, n, i + 1)\n",
        "    plt.title(\"prediction\")\n",
        "    plt.imshow(tf.squeeze(autoencoder.decoder(y_pred)), cmap='gray')\n",
        "    plt.subplot(2,n,i+1+n)\n",
        "    a = tf.reshape(val_y[i],[1,256])\n",
        "    #print(autoencoder.decoder(a).shape)\n",
        "    plt.title(\"original\")\n",
        "    plt.imshow(tf.squeeze(autoencoder.decoder(a)), cmap='gray')\n"
      ],
      "metadata": {
        "id": "L2mv_BPY7T5G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# LSTM"
      ],
      "metadata": {
        "id": "KHInss6I5UOL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_LSTM_model():\n",
        "  in_seq = tf.keras.layers.Input(shape=(seq_len, latent_dim))\n",
        "  x = tf.keras.layers.LSTM(neck_width*9)(in_seq)\n",
        "  x = tf.keras.layers.Dropout(0.1)(x)\n",
        "  x = tf.keras.layers.Dense(64, activation='relu')(x)\n",
        "  x = tf.keras.layers.Dropout(0.1)(x)\n",
        "  out = tf.keras.layers.Dense(latent_dim, activation='relu')(x)\n",
        "\n",
        "  model = tf.keras.Model(inputs=in_seq, outputs=out)\n",
        "  model.compile(optimizer='adam', loss=tf.keras.losses.MeanSquaredError())\n",
        "  return model\n",
        "\n",
        "lstm_model = make_LSTM_model()\n",
        "lstm_model.summary()"
      ],
      "metadata": {
        "id": "934IjDQJeyHM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lstm_model.fit(train_x, train_y,\n",
        "                epochs=30,\n",
        "                shuffle=True,\n",
        "                batch_size=10,\n",
        "                validation_data=(val_x, val_y)\n",
        ")"
      ],
      "metadata": {
        "id": "jN_DW-Sxe1Px"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lstm_model.save('lstm')"
      ],
      "metadata": {
        "id": "AXO6sYsSe403"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_x[0].shape)\n",
        "n = 10\n",
        "plt.figure(figsize=(20, 4))\n",
        "for i in range(n):\n",
        "    y_pred = lstm_model.predict(train_x[i:i+1])\n",
        "    plt.subplot(2, n, i + 1)\n",
        "    plt.imshow(tf.squeeze(autoencoder.decoder(y_pred)), cmap='gray')\n",
        "    plt.subplot(2,n,i+1+n)\n",
        "    a = tf.reshape(train_y[i],[1,256])\n",
        "    plt.imshow(tf.squeeze(autoencoder.decoder(a)), cmap='gray')"
      ],
      "metadata": {
        "id": "J1xw3iLVe8UU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YmrdRALUe8hX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}